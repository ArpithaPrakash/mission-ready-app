# Capstone Parsing Utilities

Utilities for converting CONOP PowerPoint files and DD2977 DRAW PDF packages into structured JSON.

## Environment Setup

1. Install Python 3.11 or later.
2. (Recommended) Create and activate a virtual environment:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## Scripts

### `parse_conop`

Parses a single CONOP PowerPoint file into structured sections.

```bash
python parse_conop.py path/to/file.pptx --output-dir PARSED_CONOPS
```

- Writes a JSON file named after the source slide deck with slugified metadata.
- Requires `python-pptx` and other packages from `requirements.txt`.

### `parse_draw.py`

Parses a single DD2977 DRAW PDF. Supports both XFA-based and text-based documents.

```bash
python parse_draw.py path/to/file.pdf --output-dir PARSED_DRAWS
```

- Attempts XFA extraction first, then falls back to text extraction.
- Produces normalized risk and approval information.

### `batch_parse_conops_draws.py`

Batch processes paired CONOP/DRAW documents grouped in subdirectories.

```bash
python batch_parse_conops_draws.py \
    "1-2CR CONOPS&DRAWs - Copy" \
    "3-2CR CONOPs&DRAWs" \
    --conops-outdir PARSED_CONOPS \
    --draws-outdir PARSED_DRAWS \
    --skip-report skipped_documents_report.json
```

- Each subdirectory receives a sequential `source_directory_id` shared by the CONOP and DRAW outputs.
- JSON outputs include `source_directory_name`, `source_directory_id`, and `source_base_directory` metadata.
- Any files that fail to parse are recorded in both the console output and the skip report.
- The skip report is a JSON document containing:
  - generation timestamp (UTC)
  - total processed directories
  - count of skipped files
  - detailed list of skipped documents with file paths, reasons, and source metadata

## Merging and Database Upload

### Merging CONOPS and DRAWs

Use the merging script to combine CONOPS and DRAW JSON files from the same directory into a single file in `MERGED_CONOPS_DRAWS/`. Each merged file is named `<directory_id>-merged.json`.

### Uploading to PostgreSQL

1. Ensure PostgreSQL is installed and running (`brew install postgresql` and `brew services start postgresql@14`).
2. Create a database and table:
   - In `psql`:
     ```sql
     CREATE DATABASE mrit_db OWNER "arpithaprakash";
     \c mrit_db
     CREATE TABLE merged_conops_draws (
         id SERIAL PRIMARY KEY,
         source_directory_id TEXT NOT NULL,
         merged_data JSONB NOT NULL
     );
     ```
3. Update `upload_merged_json_to_postgres.py` with your database credentials:
   ```python
   DB_NAME = 'mrit_db'
   DB_USER = 'arpithaprakash'
   DB_PASSWORD = 'your_password'
   DB_HOST = 'localhost'
   DB_PORT = '5432'
   ```
4. Run the script:
   ```sh
   python3 upload_merged_json_to_postgres.py
   ```
5. Verify upload in `psql`:
   ```sql
   SELECT COUNT(*) FROM merged_conops_draws;
   SELECT * FROM merged_conops_draws LIMIT 1;
   ```

## Outputs

- `PARSED_CONOPS/` and `PARSED_DRAWS/` hold JSON outputs generated by the scripts above.
- `MERGED_CONOPS_DRAWS/` contains merged JSON files for each directory.
- Filenames begin with the four-digit directory ID followed by a slugged description and a suffix indicating `-conop`, `-draw`, or `-merged`.
- Open `skipped_documents_report.json` (or the custom path supplied via `--skip-report`) to review any failures.

## Troubleshooting

- **Missing records in database**: Check for invalid or empty JSON files in `MERGED_CONOPS_DRAWS/`. Review the script output for errors or skipped files. Use logging to identify files that failed to upload.
- **"PPTX contained no extractable text"**: The PowerPoint file is likely corrupted or saved in the legacy `.ppt` format. Re-save it as a valid `.pptx` and rerun the parser.
- **"Unable to extract text" (PDF)**: Provide a text-based PDF (not a scanned image) or ensure XFA dependencies listed in `requirements.txt` are installed.
- Re-run the batch script after fixing problematic files to generate the remaining JSON outputs.
